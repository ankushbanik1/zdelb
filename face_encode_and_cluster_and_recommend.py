# -*- coding: utf-8 -*-
"""Face encode and cluster and recommend

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AErgAxqRUqrExjmtRZ0AosflaXev0HLM
"""

!pip install face_recognition

from imutils import paths
import face_recognition
import argparse
import pickle
import cv2
import os
from sklearn.cluster import KMeans
import numpy as np
from scipy.spatial import distance
import matplotlib.pyplot as plt
import operator
from scipy.stats import pearsonr

path = "dataset"
input_image = "srk1.jpg"

image = cv2.imread(input_image)
rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

boxes = face_recognition.face_locations(rgb, model="cnn")

encodings = face_recognition.face_encodings(rgb, boxes)

len(encodings[0])

"""# For new train data - creating pickle file and clustering"""

imagePaths = list(paths.list_images(path))
data_new = []

for (i, imagePath) in enumerate(imagePaths):
    image = cv2.imread(imagePath)
    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    boxes = face_recognition.face_locations(rgb, model="cnn")

    encodings = face_recognition.face_encodings(rgb, boxes)

    d = [{"imagePath": imagePath, "loc": box, "encoding": enc} for (box, enc) in zip(boxes, encodings)]
    data_new.extend(d)

f = open("final_encodings.pickle", "wb")
f.write(pickle.dumps(data_new))
f.close()

#clustering
data = pickle.loads(open("final_encodings.pickle", "rb").read())
data = np.array(data)
encodings = [d["encoding"] for d in data]
names = [d["imagePath"].split('/')[-1] for d in data]

clt = KMeans(n_clusters=3, n_jobs=-1)
clt.fit(encodings)
centers = clt.cluster_centers_
lst = clt.labels_

"""# For test data - input an image"""

image1 = cv2.imread(input_image)
rgb1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)
boxes1 = face_recognition.face_locations(rgb1, model="cnn")
encodings1 = face_recognition.face_encodings(rgb1, boxes1)
d1 = [{"loc": box, "encoding": enc} for (box, enc) in zip(boxes1, encodings1)]

dist = []
for i in range(len(centers)):
  dist.append(distance.cosine(centers[i], d1[0]['encoding']))

final_images = []
for i in range(len(lst)):
  if lst[i] == dist.index(min(dist)):
    final_images.append(names[i])

"""# Recommending 5 images"""

IMG_SIZE=70

img = cv2.imread(input_image, cv2.IMREAD_GRAYSCALE)
new_array = cv2.resize(img, (IMG_SIZE, IMG_SIZE))
length = np.prod(new_array.shape)
new_array = new_array.reshape(length)

diff = {}
for img in final_images:
  img1 = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)
  new_array1 = cv2.resize(img1, (IMG_SIZE, IMG_SIZE))
  length = np.prod(new_array1.shape)
  new_array1 = new_array1.reshape(length)
  diff[img] = abs(distance.cosine(new_array1, new_array))
    
sorted_diff = dict(sorted(diff.items(), key=operator.itemgetter(1)))
final = list(sorted_diff.keys())
final_cosine = final[:20]

diff = {}
for img in final_images:
  img1 = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)
  new_array1 = cv2.resize(img1, (IMG_SIZE, IMG_SIZE))
  length = np.prod(new_array1.shape)
  new_array1 = new_array1.reshape(length)
  diff[img] = abs(distance.jaccard(new_array1, new_array))
    
sorted_diff = dict(sorted(diff.items(), key=operator.itemgetter(1)))
final = list(sorted_diff.keys())
final_jaccard = final[:20]

diff = {}
for img in final_images:
  img1 = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)
  new_array1 = cv2.resize(img1, (IMG_SIZE, IMG_SIZE))
  length = np.prod(new_array1.shape)
  new_array1 = new_array1.reshape(length)
  diff[img] = abs(pearsonr(new_array1, new_array)[0])
    
sorted_diff = dict(sorted(diff.items(), key=operator.itemgetter(1)))
final = list(sorted_diff.keys())
final_pearson = final[-20:]

ultimate = []
for i in final_cosine:
  if i in final_jaccard:
    if i in final_pearson[::-1]:
      ultimate.append(i)

"""# Showing input and recommended images"""

print('INPUT IMAGE\n')
img1 = cv2.imread(input_image)
img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)
plt.imshow(img1)
plt.show()

print('RECOMMENDED IMAGES')
for img in ultimate[:5]:
  img1 = cv2.imread(os.path.join(path,img))
  img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)
  plt.imshow(img1)
  plt.show()

!pip3 freeze > requirements.txt

